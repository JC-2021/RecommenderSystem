{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Movie Recommender System with Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we will be using is **Kaggle MovieLens 20M dataset.**\n",
    "\n",
    "The dataset describes ratings and free-text tagging activities from MovieLens, a movie recommendation service. It contains 20000263 ratings and 465564 tag applications across 27278 movies. These data were created by 138493 users between January 09, 1995 and March 31, 2015. This dataset was generated on October 17, 2016.\n",
    "\n",
    "Users were selected at random for inclusion. All selected users had rated at least 20 movies.\n",
    "\n",
    "In this dataset, we are interested in the **rating.csv** file specifically,.\n",
    "\n",
    "The **rating.csv** file contains ratings of movies by users. It has following columns:\n",
    "\n",
    "userId, movieId, rating, timestamp.\n",
    "\n",
    "We are interested in **userId, movieId and rating.** The range of rating is 0~5. The actual min value of ratings in the dataset is 0.5. The actual max value of ratings in the dataset is 5.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the following codes, we firstly need to download the **rating.csv** file in the link provided below. After downloading the file, we need to put the file in the **same directory** as this notebook. \n",
    "There is no need for other files in the dataset for building the recommender system. The **rating.csv** file is enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link for the MovieLens 20M dataset: https://www.kaggle.com/grouplens/movielens-20m-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/AZ4qOOn.png\"  width=\"1000\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sortedcontainers import SortedList\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender_System():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize the field variables\n",
    "        self.user2movie_train={}\n",
    "        self.movie2user_train={}\n",
    "        self.rating_train={}\n",
    "        self.user2movie_test={}\n",
    "        self.movie2user_test={}\n",
    "        self.rating_test={}\n",
    "        self.ratings_average = None\n",
    "        self.ratings_deviation = None \n",
    "        self.users_neigbors = None\n",
    "    \n",
    "    \n",
    "    def load(self,path):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function loads the file Rating.csv, turns it to a pandas dataframe.\n",
    "        \n",
    "        If other files are passed into this function, minor adjustment may be needed.\n",
    "        \"\"\"   \n",
    "        \n",
    "        df = pd.read_csv(path,header='infer')\n",
    "        \n",
    "        return df        \n",
    "    \n",
    "    def reframe(self,path):\n",
    "              \n",
    "        \"\"\"\n",
    "        This function reframes the dataframe.\n",
    "        \n",
    "        If other files are passed into the \"load\" function, minor adjustment may be needed here when reframing.\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Reframing the data...\")\n",
    "        df = self.load(path).drop(columns=[\"timestamp\"]) \n",
    "        \n",
    "        # set userId index starting from zero\n",
    "        df['userId'] = df['userId'] - 1\n",
    "        \n",
    "        # Reset movieId index to be continuous      \n",
    "        set_of_movie_ids = sorted(set(df['movieId'].values))    \n",
    "        reset_movies = self.reset(set_of_movie_ids)       \n",
    "        df['movieId'] = df['movieId'].apply(lambda r:reset_movies[r])\n",
    "        \n",
    "        print(\"Done.\")       \n",
    "        return df\n",
    "                \n",
    "    def reduce(self,df,N,M):\n",
    "        \n",
    "        print(\"Reducing the data...\")\n",
    "        users = self.counter(df['userId'].values)\n",
    "        movies = self.counter(df['movieId'].values)\n",
    "        top_users = [x[0] for x in sorted(users.items(),key=lambda x: x[1],reverse=True)[:N]]\n",
    "        top_movies = [x[0] for x in sorted(movies.items(),key=lambda x: x[1],reverse=True)[:M]]\n",
    "        df = df[df['userId'].isin(top_users) & df['movieId'].isin(top_movies)]\n",
    "        \n",
    "        # reset user and movie index to make it continuous\n",
    "        \n",
    "        set_of_user_ids = sorted(set(df['userId'].values))\n",
    "        set_of_movie_ids = sorted(set(df['movieId'].values))\n",
    "        reset_users = self.reset(set_of_user_ids)\n",
    "        reset_movies = self.reset(set_of_movie_ids)\n",
    "        df['userId'] = df['userId'].apply(lambda r: reset_users[r])\n",
    "        df['movieId'] = df['movieId'].apply(lambda r: reset_movies[r])\n",
    "        print(\"Done.\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "            \n",
    "    def mapping_training_set(self,row):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function creates user2movie, movie2user, and rating maps of the training dataset by row.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        i = row['userId']\n",
    "        j = row['movieId']\n",
    "        if i not in self.user2movie_train:\n",
    "            self.user2movie_train[i] = [j]\n",
    "        else:\n",
    "            self.user2movie_train[i].append(j)\n",
    "\n",
    "        if j not in self.movie2user_train:\n",
    "            self.movie2user_train[j] = [i]\n",
    "        else:\n",
    "            self.movie2user_train[j].append(i)\n",
    "            \n",
    "        self.rating_train[(i,j)] = row['rating']            \n",
    "\n",
    "        \n",
    "    def mapping_test_set(self,row):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function creates user2movie, movie2user, and rating maps of the test dataset by row.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        i = row['userId']\n",
    "        j = row['movieId']\n",
    "        \n",
    "        # No need to create user2movie_test and movie2user_test, though we can\n",
    "        # If we want to create user2movie_test and movie2user_test, just copy the pattern in \"mapping_training_set\" function\n",
    "        \n",
    "        if i not in self.user2movie_test:\n",
    "            self.user2movie_test[i] = [j]\n",
    "        else:\n",
    "            self.user2movie_test[i].append(j)\n",
    "\n",
    "        if j not in self.movie2user_test:\n",
    "            self.movie2user_test[j] = [i]\n",
    "        else:\n",
    "            self.movie2user_test[j].append(i) \n",
    "            \n",
    " \n",
    "        self.rating_test[(i,j)] = row['rating']    \n",
    "        \n",
    "    def mapping(self,df,train_test_split):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function uses pd.apply method combined with \"mapping_training_set\" and \"mapping_test_set\" function\n",
    "        \n",
    "        to create user2movie, movie2user, and rating maps.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        N = len(set(df['userId'].values)) \n",
    "        M = len(set(df['movieId'].values)) \n",
    "        again = True\n",
    "        print(\"Mapping the data...\")\n",
    "        while again == True:\n",
    "            # shuffle the dataframe\n",
    "            df = df.sample(frac=1)\n",
    "            df_len = len(df)\n",
    "            df_train = df.iloc[:int(train_test_split*df_len)]\n",
    "            df_test = df.iloc[int(train_test_split*df_len):]\n",
    "            # pass it to variables a and b in order to suppress the results\n",
    "            a = df_train.apply(self.mapping_training_set,axis=1)\n",
    "            b = df_test.apply(self.mapping_test_set,axis=1)\n",
    "            L1 = len(list(self.user2movie_train.keys()))\n",
    "            L2 = len(list(self.user2movie_test.keys()))\n",
    "            L3 = len(list(self.movie2user_train.keys()))\n",
    "            L4 = len(list(self.movie2user_test.keys()))\n",
    "            if L1==N and L2 ==N and L3==M and L4==M:\n",
    "                # Sort maps, userId and movieId both start from 0\n",
    "                self.user2movie_train = {x[0]:x[1] for x in tqdm(sorted(self.user2movie_train.items(),key=lambda x:x[0]))}\n",
    "                self.user2movie_test = {x[0]:x[1] for x in tqdm(sorted(self.user2movie_test.items(),key=lambda x:x[0]))}\n",
    "                self.movie2user_train = {x[0]:x[1] for x in tqdm(sorted(self.movie2user_train.items(),key=lambda x:x[0]))}\n",
    "                self.movie2user_train = {x[0]:x[1] for x in tqdm(sorted(self.movie2user_train.items(),key=lambda x:x[0]))}   \n",
    "                again=False\n",
    "                print(\"Done.\")\n",
    "                \n",
    "    def personalized_weights(self,df,train_test_split,threshold,k_nearest):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is the core of collaborative filtering recommender system algorithm.\n",
    "        \n",
    "        It defines the personalized weight for each pair of users. The correlation between two users\n",
    "        \n",
    "        are defined by Pearson coefficient.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.mapping(df,train_test_split)\n",
    "        self.ratings_average = [] # Each user's average rating on all movies he or she has rated\n",
    "        self.ratings_deviation = [] # Each user's deviation on all movies he or she has rated, a list of dictionary\n",
    "        self.users_neigbors = [] # Each user's k-nearest neigbors' weights. For each user, it is a SortedList object of k-nearest neighbors, in which the information of each neighbor of the user is stored as a tuple (weights,userId)\n",
    "        N = len(set(df['userId'].values))\n",
    "        print(\"Generating personalized weights...\")\n",
    "        for i in tqdm(range(N)):\n",
    "            movies_for_i = self.user2movie_train[i]\n",
    "            # set is used for intersection between user i and user j later\n",
    "            movies_for_i_set = set(movies_for_i)\n",
    "            # a dictionary where key is the movieId, value is the rating that user i gives to this movie\n",
    "            ratings_for_i={movie:self.rating_train[(i,movie)] for movie in movies_for_i_set}\n",
    "            average_for_i = np.mean(list(ratings_for_i.values()))\n",
    "            # a dictionary of each movie corresponding to a deviation of rating\n",
    "            deviation_for_i = {movie:(rating-average_for_i) for movie,rating in ratings_for_i.items()}\n",
    "            deviation_i_values = np.array(list(deviation_for_i.values()))\n",
    "            # standard deviation for pearson coefficient\n",
    "            sigma_i = np.sqrt(deviation_i_values.dot(deviation_i_values))\n",
    "            self.ratings_average.append(average_for_i)\n",
    "            self.ratings_deviation.append(deviation_for_i)\n",
    "            # Establish a SortedList object (similar to java)\n",
    "            sorted_list = SortedList()\n",
    "            # Compute the weights between two users\n",
    "            for j in range(N):\n",
    "                # No need to compute weights for the user itself since we don't use the information of user who needs \n",
    "                #to be recommended to recommend the user itself\n",
    "                if i != j:\n",
    "                    movies_for_j = self.user2movie_train[j]\n",
    "                    movies_for_j_set = set(movies_for_j)\n",
    "                    movie_intersect = (movies_for_i_set & movies_for_j_set)\n",
    "                    # Abandon if two users have too few common items that they share because in that case not much\n",
    "                    # useful information will be provided. It could speed up the algorithm.\n",
    "                    if len(movie_intersect) > threshold:\n",
    "                        ratings_for_j={movie:self.rating_train[(j,movie)] for movie in movies_for_j_set}\n",
    "                        average_for_j = np.mean(list(ratings_for_j.values()))\n",
    "                        # a dictionary of each movie corresponding to a deviation of rating\n",
    "                        deviation_for_j = {movie:(rating-average_for_j) for movie,rating in ratings_for_j.items()}\n",
    "                        deviation_j_values = np.array(list(deviation_for_j.values()))\n",
    "                        sigma_j = np.sqrt(deviation_j_values.dot(deviation_j_values))\n",
    "                        # Compute the weight between two users with pearson cofficient\n",
    "                        numerator = np.sum(deviation_for_i[m]*deviation_for_j[m] for m in movie_intersect)\n",
    "                        denominator = sigma_i*sigma_j\n",
    "                        w_i_j = numerator/denominator\n",
    "\n",
    "                        # Note: Since SortedList sorts in ascending order, in order to get highest weights \n",
    "                        #(k-nearest) we want, we add a minus sign before the weight. \n",
    "                        # Later when doing recommendation, the minus sign should be dropped. We could also try the absolute value.\n",
    "                        sorted_list.add((-w_i_j,j)) # j is user\n",
    "                        \n",
    "                        # Drop the rest of weights. Always keep only k-length neighbors (or less), to save space.\n",
    "                        if len(sorted_list) > k_nearest:\n",
    "                            del sorted_list[-1]\n",
    "\n",
    "            self.users_neigbors.append(sorted_list)\n",
    "        \n",
    "        print(\"Done.\")\n",
    "            \n",
    "            \n",
    "    def recommend(self,user_index,movie_index):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function receives a userId and movieId, then predicts a rating that the user would give to the movie.\n",
    "        \n",
    "        In other words, this function proceeds actual recommendation.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for weight, user_j in self.users_neigbors[user_index]:\n",
    "            # If user_j happens not to rate the movie_j that user_i rates, then go to the Exception, which directly passes\n",
    "            # We could also \"find out \" if user_j has rated the movie_j, but that would cost the time of finding items in\n",
    "            # dictionary, which is not efficient. Therefore, we use try except statement.\n",
    "            \n",
    "            try:\n",
    "                # add a second minus sign to weight to make it positive again\n",
    "                numerator+=(-weight)*(self.ratings_deviation[user_j][movie_index])\n",
    "                denominator+= abs(weight)\n",
    "\n",
    "            except:\n",
    "\n",
    "                pass\n",
    "        # There might be an extreme case that this user's all neighbor users have not rated the movie that is supposed to\n",
    "        # be recommended to this user. In this case, the recommendation of this movie would have to be the average of this  \n",
    "        # user's rating.\n",
    "        if denominator == 0:\n",
    "            prediction = self.ratings_average[user_index]\n",
    "        \n",
    "        else:\n",
    "            prediction = (numerator/denominator)+ self.ratings_average[user_index]\n",
    "\n",
    "        # ADD boundary (0.5-5) here\n",
    "\n",
    "        return prediction\n",
    "    \n",
    "    def root_mean_square_error(self,predictions,labels):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function receives the predicted ratings and the true ratings,\n",
    "        \n",
    "        and then computes the root mean square error of the prediction.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)        \n",
    "        rmse = np.sqrt(np.mean((predictions - labels)**2))\n",
    "        \n",
    "        return rmse\n",
    "        \n",
    "        \n",
    "    def reset(self,obj):\n",
    "        \n",
    "        \"\"\"\n",
    "        helper function: Reset index of dataframe.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        reset_index = {}\n",
    "        count = 0\n",
    "        for i in obj:\n",
    "            reset_index[i] = count\n",
    "            count+=1\n",
    "        \n",
    "        return reset_index\n",
    "  \n",
    "                \n",
    "    def counter(self,obj):\n",
    "        \n",
    "        \"\"\"\n",
    "        helper function: Count the object of interest.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        counter = {}\n",
    "        \n",
    "        for item in obj:\n",
    "            \n",
    "            if item not in counter:\n",
    "                \n",
    "                counter[item] = 0\n",
    "            \n",
    "            counter[item]+=1\n",
    "        \n",
    "        return counter       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substantiate the recommender system class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_system = Recommender_System()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess and reframe the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reframing the data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "df_reframed = recommender_system.reframe(\"./rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the dataframe to top 1000 users and 200 movies for the purpose of illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We choose top 1000 users who have rated the most movies, and top 200 movies which have been rated the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing the data...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/liangchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_reduced = recommender_system.reduce(df_reframed,N=1000,M=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute personalized weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do recommendation, the personalized weights are computed. First the dataset is split into training and test set with a ratio of 4:1. Then, a threshold = 5 is set for the least\n",
    "number of common movies that two users have rated. If the number of movies that two users both have rated is less than 5, then there is no need to compute the weights between these two users share too little information. If two\n",
    "users share too little information, it's not accurate enough to predict one user's behavior based on another.\n",
    "\n",
    "A k-nearest neighbor value = 25 is also set for users that are most in common. When doing the prediction on one user, we would like to use the top 25 neighboring users who are the most similar to this user. We could also use all the other users to do prediction, but by setting an adequate k-nearest neighbor value, we can speed up the algorithm as well as reserve the accuracy of prediction. k_nearest=25 is enough to do the recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 896985.46it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 313101.22it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 285423.89it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 169193.38it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]/Users/liangchen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:207: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Generating personalized weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [04:00<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender_system.personalized_weights(df_reduced,train_test_split=0.8,threshold=5,k_nearest=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we do the recommendation by predicting the rating that a user would give to a movie.\n",
    "If the predicted rating is high, then we recommend this movie to the user, vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_test = recommender_system.rating_test\n",
    "predictions = []\n",
    "labels = []\n",
    "for (user,movie),rating in rating_test.items():    \n",
    "    prediction = recommender_system.recommend(int(user),int(movie))\n",
    "    predictions.append(prediction)\n",
    "    labels.append(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute root mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There isn't a fix method for evaluating the collaborative filtering recommender system. In this project, we would like to evaluate the model by computing the root mean square error (RMSE) between the predicted rating and the true rating on the test dataset. \n",
    "The RMSE is around 0.77, which is a pretty good result for the collaborative filtering recommender system. The RMSE benchmark for recommender system is around 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7709174962124318"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = recommender_system.root_mean_square_error(predictions,labels)\n",
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
